---
title: "HW5"
author: "jgn2108"
date: "`r Sys.Date()`"
output: github_document
---

## Problem 1: Washington Post data in a github repository
```{r}
#install.packages("readr")
#install.packages("skimr")
#library(readr)
#library(tidyverse)
#library(skimr)
#library(dplyr)
#library(broom)
#library(purrr)
#library(broom)
#library(ggplot2)
```

#Read in data
```{r}
url <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

# Read the CSV file into a data frame
homicide_data <- read_csv(url)

# View the first few rows of the data
head(homicide_data)
```
#Data cleaning (using skimr)
```{r}
# Use the skim() function directly from skimr without loading the whole package
skim_summary <- skimr::skim(homicide_data)

# Print the summary
print(skim_summary)

```
#Convert tibble into a standard df
```{r}
homicide_data_df <- as.data.frame(homicide_data)
str(homicide_data_df)
```
This data represents the names and demographics of homicide victims across the U.S., as well as the date the homicide was reported, the location (latitude/longitude) the victims were found, and the disposition of the case (i.e., whether an arrest was made or not).

#Reformat reported_date
```{r}
# Convert numeric date to Date object
homicide_data_df$reported_date <- as.Date(as.character(homicide_data_df$reported_date), format = "%Y%m%d")

# Format the date as MM/DD/YYYY
homicide_data_df$reported_date <- format(homicide_data_df$reported_date, "%m/%d/%Y")

```

#Create a new variable: city_state
```{r}
# Create city_state variable
homicide_data_df <- mutate(homicide_data_df, city_state = paste(city, state, sep = ", "))

# Summarize data
summary_data <- homicide_data_df %>%
  group_by(city_state) %>%
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )

# Print the summary data
print(summary_data)
```
This new variable allows me to clearly see the total homicides vs. unsolved homicides by city/state.

#Now use the prop.test and broom::tidy functions for the subset of data related to Baltimore, MD
```{r}
# Subset data for Baltimore, MD
baltimore_data <- filter(homicide_data_df, city == "Baltimore" & state == "MD")

# Use prop.test to estimate the proportion of unsolved homicides
prop_test_result <- prop.test(
  sum(baltimore_data$disposition %in% c("Closed without arrest", "Open/No arrest")),
  nrow(baltimore_data)
)

# Now, apply broom::tidy to the prop.test result and print tidy results
tidy_result <- tidy(prop_test_result)
print(tidy_result)

# Extract estimated proportion and CIs
estimated_proportion <- tidy_result$estimate[1] #but i'm having trouble getting CIs

# Check if conf.int is available 
if (!is.null(tidy_result$conf.int)) {
  conf_int <- tidy_result$conf.int
  cat("Confidence Intervals:", conf_int[1], "to", conf_int[2], "\n")
} else {
  cat("Confidence Intervals: Not available\n")
}

# Print the estimated proportion
cat("Estimated Proportion of Unsolved Homicides:", estimated_proportion, "\n")

```
Estimated Proportion of Unsolved Homicides: 0.6455607 
Confidence Intervals: Not available

#trouble shooting why I can't get a CI
```{r}
#Make Balitimore data into a normal df and then see if there is missing data
baltimore_data_df <- as.data.frame(baltimore_data)
missing_rows <- complete.cases(baltimore_data_df)

# Subset the data to show only rows with missing observations
rows_with_missing <- baltimore_data_df[!missing_rows, ]

# Display rows with missing observations
print(rows_with_missing) #No missing data
```

#still trouble shooting why I can't get CIs
```{r}
#look into structure of tidy results
str(tidy_result) #AHHHH, the CIs are conf_int_low and conf_int_high

# Extract CIs and print
conf_int_low <- tidy_result$conf.low
conf_int_high <- tidy_result$conf.high
cat("Confidence Intervals:", conf_int_low, "to", conf_int_high, "\n")

```
Confidence Intervals: 0.6275625 to 0.6631599

#Now, I have to begin interating my commands using the prop.test function
```{r}
# Create a tidy pipeline
all_cities_results <- homicide_data_df %>%
  group_by(city) %>%
  nest() %>%
  mutate(
    prop_test_result = map(data, ~ {
      unsolved_homicides <- sum(.x$disposition %in% c("Closed without arrest", "Open/No arrest"))
      total_homicides <- nrow(.x)
      
      if (unsolved_homicides == 0) {
        # Handle cases where the number of unsolved homicides is zero
        return(tibble(estimate = 0, conf.low = 0, conf.high = 0))
      }
      
      prop.test(unsolved_homicides, total_homicides)
    }),
    tidy_result = map(prop_test_result, tidy)
  ) %>%
  unnest(tidy_result) %>%
  select(city, estimate, conf.low, conf.high)

# Print the proportions of unsolved murders and CIs for all cities 
print(all_cities_results)

```

#Now I have to use ggplot2 and geom_errorbar to create a plot that shows the estimated proportions and CIs for each city
```{r}
# Create a ggplot
ggplot(all_cities_results, aes(x = reorder(city, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(title = "Proportion of Unsolved Homicides by City",
       x = "City",
       y = "Proportion of Unsolved Homicides") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip()

```

##Problem 2: longitudinal study with control arm vs. experimental arm
```{r}
#read in data (20 csv files)
directory_path <- "~/Desktop/P8105/HW5/data"

```

#Begin iterating to combine 20 csv files into one df
```{r}
# Get a list of all CSV files in the directory
csv_files <- list.files(path = directory_path, pattern = "\\.csv$", full.names = TRUE)

# Initialize an empty list to store dfs
data_frames <- list()

# Iterate through each CSV file
for (file in csv_files) {
  # Read the CSV file
  df <- read.csv(file, header = TRUE)
  
  # Extract subject ID and arm from the file name
  file_parts <- str_split_fixed(basename(file), "_", n = 2)
  subject_id <- file_parts[, 1]
  arm <- file_parts[, 2]
  
  # Add subject ID and arm as columns
  df <- df %>%
    mutate(subject_id = subject_id, arm = arm)
  
  # Append the data frame to the list
  data_frames <- append(data_frames, list(df))
}

# Combine all data frames into a single tidy dataframe
combined_data <- bind_rows(data_frames)

# View the resulting dataframe
print(combined_data)

```

#Now use the map function from the purrr package to iterate over the file names and read in data for each subject (RegEx)
```{r}
# Read in data for each subject and save it as a new variable
combined_data.1 <- tibble(file = csv_files) %>%
  mutate(data = map(file, read_csv)) %>%
  unnest(data)

# Extract subject ID and arm from the file name
combined_data.1 <- combined_data.1 %>%
  mutate(
    subject_id = str_extract(file, "(?<=con_|exp_)\\d+"),  # Extract numeric part immediately following "con" or "exp"
    arm = str_extract(file, "(con|exp)")  # Extract "con" or "exp" from file name
  )


# View the resulting dataframe
print(combined_data.1)
```

#Make them into a traditional df (from a tibble because tibbles look too visiually complex for me)
```{r}
combined_data1_df <- as.data.frame(combined_data.1)
str(combined_data1_df)
```

